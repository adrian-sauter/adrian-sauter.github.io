---

@article{traub2023loci,
  title={Loci-Segmented: Improving Scene Segmentation Learning},
  author={Traub, Manuel and Becker, Frederic and Sauter, Adrian and Otte, Sebastian and Butz, Martin V},
  journal={arXiv preprint arXiv:2310.10410},
  year={2023},
  abstract={Current slot-oriented approaches for compositional scene segmentation from images and videos rely on provided background information or slot assignments. We present a segmented location and identity tracking system, Loci-Segmented (Loci-s), which does not require either of this information. It learns to dynamically segment scenes into interpretable background and slotbased object encodings, separating rgb, mask, location, and depth information for each. The results reveal largely superior video decomposition performance in the MOVi datasets and in another established dataset collection targeting scene segmentation. The system’s well-interpretable, compositional latent encodings may serve as a foundation model for downstream tasks.},
  pdf={Loci-Segmented.pdf},
  preview={loci-segmented_preview.png},
  selected={true},
  bibtex_show = {true}
}

@article{sauter2024studying,
  title={{\textquotedblleft}Studying How to Efficiently and Effectively Guide Models with Explanations{\textquotedblright} - A Reproducibility Study},
  author={Adrian Sauter and Milan Miletić and Ryan Ott and Rohith Saai Pemmasani Prabakaran},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2024},
  url={https://openreview.net/forum?id=9ZzASCVhDF},
  abstract={Model guidance describes the approach of regularizing the explanations of a deep neural network model towards highlighting the correct features to ensure that the model is “right for the right reasons”. Rao et al. (2023) conducted an in-depth evaluation of effective and efficient model guidance for object classification across various loss functions, attributions methods, models, and 'guidance depths' to study the effectiveness of different methods. Our work aims to (1) reproduce the main results obtained by Rao et al. (2023), and (2) propose several extensions to their research. We conclude that the major part of the original work is reproducible, with certain minor exceptions, which we discuss in this paper. In our extended work, we point to an issue with the Energy Pointing Game (EPG) metric used for evaluation and propose an extension for increasing its robustness. In addition, we observe the EPG metric’s predisposition towards favoring larger bounding boxes, a bias we address by incorporating a corrective penalty term into the original Energy loss function. Furthermore, we revisit the feasibility of using segmentation masks in light of the original study’s finding that minimal annotated data can significantly boost model performance. Our findings suggests that Energy loss inherently guides models to on-object features without the requirement for segmentation masks. Finally, we explore the role of contextual information in object detection and, contrary to the assumption that focusing solely on object-specific features suffices for accurate classification, our findings suggest the importance of contextual cues in certain scenarios. Code available at: https://github.com/ryan-ott/model-guidance-reproducibility.},
  pdf={2240_Studying_How_to_Efficient.pdf},
  preview={model-guidance_preview.png},
  selected={true},
  poster      = {https://docs.google.com/presentation/d/1CW69wFyC46pvTutPMqTGxhl3_ckyCw4B/edit?usp=sharing&ouid=112476999759097241984&rtpof=true&sd=true},
  bibtex_show = {true}
}   

@article{zhang2021explainable,
  title={Explainable semantic space by grounding language to vision with cross-modal contrastive learning},
  author={Zhang, Yizhen and Choi, Minkyu and Han, Kuan and Liu, Zhongming},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18513--18526},
  year={2021},
  bibtex_show={true},
  abbr = {NeurIPS},
  selected={false}
}

@article{searle1980minds,
  title={Minds, brains, and programs},
  author={Searle, John R},
  journal={Behavioral and brain sciences},
  volume={3},
  number={3},
  pages={417--424},
  year={1980},
  publisher={Cambridge University Press},
  bibtex_show={true},
  abbr={BBS},
  selected={false}
}

@article{stroop1935studies,
  title={Studies of interference in serial verbal reactions.},
  author={Stroop, J Ridley},
  journal={Journal of experimental psychology},
  volume={18},
  number={6},
  pages={643},
  year={1935},
  publisher={Psychological Review Company},
  bibtex_show={true},
  abbr={J. Exp. Psychol.},
  selected={false}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PmLR},
  bibtex_show={true},
  abbr={ICML},
  selected={false}
}

@article{tenney2019bert,
  title={BERT rediscovers the classical NLP pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  journal={arXiv preprint arXiv:1905.05950},
  year={2019},
  bibtex_show={true},
  abbr={ACL},
  selected={false}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014},
  bibtex_show={true},
  abbr={ICLR},
  selected={false}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019},
  bibtex_show={true},
  abbr={ACL},
  selected={false}
}